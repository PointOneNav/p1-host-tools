import io
import logging
import time
from argparse import Namespace
from pathlib import Path
from typing import Any, Dict, Optional

import paramiko
from scp import SCPClient

from bin.config_tool import request_shutdown
from p1_hitl.defs import UPLOADED_LOG_LIST_FILE, HitlEnvArgs
from p1_hitl.get_build_artifacts import download_file
from p1_runner.device_interface import DeviceInterface
from p1_runner.device_type import DeviceType
from p1_test_automation.devices_config import DeviceConfig, open_data_source

from .base_interfaces import HitlDeviceInterfaceBase
from .interface_utils import enable_imu_output

RESTART_WAIT_TIME_SEC = 10
PROCESS_STOP_TIMEOUT_SEC = 10
OUTPUT_PORT = 30200
DIAGNOSTIC_PORT = 30202

SSH_USERNAME = "pointone"
SSH_KEY_PATH = "/home/pointone/.ssh/id_ed25519"


class HitlBigEngineInterface(HitlDeviceInterfaceBase):
    LOGGER = logging.getLogger('point_one.hitl.hitl_interface')
    DEVICE_NAME = ""
    VERSION_PREFIX = ""
    TAR_FILENAME_PREFIX = ""
    TAR_FILENAME_SUFFIX = ""
    RUNNER_CMD = ""
    # NOTE: This assumes the process binary is named `fusion_engine`. This may need to be child class specific
    # if this can't be assumed.
    STOP_CMD = 'pkill -SIGTERM -e fusion_engine'
    KILL_CMD = 'pkill -SIGKILL -e fusion_engine'

    @staticmethod
    def get_device_config(args: HitlEnvArgs) -> Optional[DeviceConfig]:
        if not args.check_fields(['JENKINS_LAN_IP']):
            return None
        else:
            # Interface is TCP3, which is configured as the diagnostic port.
            return DeviceConfig(name=args.HITL_NAME,
                                tcp_address=args.JENKINS_LAN_IP,
                                port=DIAGNOSTIC_PORT
                                )

    def __init__(self, config: DeviceConfig, env_args: HitlEnvArgs):
        self.config = config
        self.env_args = env_args
        self.device_interface: Optional[DeviceInterface] = None
        self.ssh_client: Optional[paramiko.SSHClient] = None
        self.ssh_channel: Optional[paramiko.Channel] = None

    def _check_process_exit(self) -> bool:
        if self.ssh_client is not None and self.ssh_channel is not None:
            if not self.ssh_channel.exit_status_ready():
                self.LOGGER.error('FE process still running after shutdown timeout.')
                return False
            elif not self.ssh_channel.recv_ready():
                self.LOGGER.error("Missing return code string.")
                return False
            else:
                console_output = ''
                # Even if process is ended, may need multiple reads.
                while True:
                    read_str = self.ssh_channel.recv(10240).decode(errors='ignore')
                    if len(read_str) == 0:
                        break
                    console_output += read_str

                lines = console_output.splitlines()
                try:
                    ret_code = int(lines[-1])
                    # return codes > 128 indicate a signal triggered the termination (subtract 128 for the error code to
                    # get the corresponding signal). Codes 1,2,9,10,12-15 are signals that may be generated by external
                    # sources (SIGHUP, SIGKILL, etc.) so they don't indicate an internal failure.
                    # https://man7.org/linux/man-pages/man7/signal.7.html
                    # https://faculty.cs.niu.edu/~hutchins/csci480/signals.htm
                    if ret_code in [0, 129, 130, 137, 138, 140, 141, 142, 143]:
                        self.LOGGER.info(f"FE process exited successfully with code: {ret_code}")
                        return True
                    else:
                        self.LOGGER.error(f"FE process exited with error code: {ret_code}")
                        self.LOGGER.error("Process final output:\n" + ('='*80) + '\n' + console_output + ('='*80))
                        return False
                except ValueError as e:
                    self.LOGGER.error(f"Could not parse return code: {e}")
                    return False
        self.LOGGER.warning(f"FE process wasn't started.")
        return True

    def init_device(self, build_info: Dict[str, Any], skip_reset=False,
                    skip_corrections=False) -> Optional[DeviceInterface]:
        # build_info example:
        # {
        #     "timestamp": 1725918926,
        #     "version": "v2.1.0-917-g7e74d1b235",
        #     "git_hash": "7e74d1b2356165d0e4408aa665ebf214e8a6dcb3",
        #     "aws_path": "s3://pointone-build-artifacts/nautilus/quectel/v2.1.0-917-g7e74d1b235/"
        # }

        self.LOGGER.info(f'Initializing {self.DEVICE_NAME}.')

        if self.config.tcp_address is None:
            raise KeyError('Config missing TCP address.')

        pkey = paramiko.Ed25519Key.from_private_key_file(SSH_KEY_PATH)

        # Set up SSH automation tool.
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        self.LOGGER.info(f'Attempting to connect to TCP address {self.config.tcp_address}')
        try:
            ssh_client.connect(self.config.tcp_address, username=SSH_USERNAME, pkey=pkey)
        except Exception as e:
            self.LOGGER.error("Failed to connect to TCP address %s: %s" % (self.config.tcp_address, str(e)))
            return None

        # Check for successful connection.
        transport = ssh_client.get_transport()
        if transport is None or not transport.is_active():
            self.LOGGER.error('Failed to connect to TCP address.')
            return None

        # Stop any existing runs.
        ssh_client.exec_command(self.KILL_CMD)
        # Clear all files from previous runs.
        ssh_client.exec_command("rm -rf p1_fusion_engine*")

        # Clear all previously recorded logs.
        ssh_client.exec_command("rm -rf /logs/*")

        # Download release from S3.
        aws_path = build_info["aws_path"]
        version_str = build_info["version"]
        tar_filename = "%s%s%s" % (self.TAR_FILENAME_PREFIX,
                                   version_str[len(self.VERSION_PREFIX):],
                                   self.TAR_FILENAME_SUFFIX)

        fd = io.BytesIO()

        if not download_file(fd, aws_path, tar_filename):
            self.LOGGER.error("Failed to download file %s from %s" % (tar_filename, aws_path))
            return None

        fd.seek(0)
        scp = SCPClient(transport)
        scp.putfo(fd, f'/home/pointone/{tar_filename}')

        # Unzip the tar file.
        _stdin, _stdout, _stderr = ssh_client.exec_command(f"tar -xzf {tar_filename}")
        # Wait for exit status to ensure that tar command finished executing.
        exit_status = _stdout.channel.recv_exit_status()

        # Run bootstrap script.
        channel = transport.open_session()
        self.ssh_client = ssh_client
        self.ssh_channel = channel

        RUNNER_CMD_PREFIX = ''
        if skip_corrections:
            # This is made a little confusing by the sshd_config AcceptEnv parameter. I believe this means we can use
            # the paramiko set_environment_variable or other methods for passing in environment variables. However,
            # using normal shell methods within the SSH session to set environment variables still works.
            #
            # The scripts are setup not to override this value if it is set and to default to "auto" otherwise.
            RUNNER_CMD_PREFIX = 'CORRECTIONS_SOURCE="none" '

        self.LOGGER.info('Starting engine.')

        # From https://docs.paramiko.org/en/stable/api/channel.html:
        #  Because SSH2 has a windowing kind of flow control, if you stop reading data from a Channel and its buffer
        #  fills up, the server will be unable to send you any more data until you read some of it.
        # To handle this, all output is passed into tail to avoid needing to continuously read data over the SSH
        # connection. This creates an issue where the return code of this call is the exit code of `tail`. Using
        # `PIPESTATUS` gets the exit code of the FE process dumped to stdout.
        # Note that the newline in the echo is automatically escaped in the exec_command.
        BUFFER_OUTPUT_AND_EXIT_CODE = ' 2>&1 | tail -n 100; echo "\n${PIPESTATUS[0]}"'
        channel.set_combine_stderr(True)
        self.LOGGER.info((RUNNER_CMD_PREFIX + self.RUNNER_CMD + BUFFER_OUTPUT_AND_EXIT_CODE).replace('\n', '\\n'))
        channel.exec_command(RUNNER_CMD_PREFIX + self.RUNNER_CMD + BUFFER_OUTPUT_AND_EXIT_CODE)
        # Manually wait to ensure that the bootstrap script kicks off in the background before continuing.
        time.sleep(RESTART_WAIT_TIME_SEC)

        # See if bootstrap script exited early.
        if channel.exit_status_ready():
            self.LOGGER.error('Fusion engine process exited prematurely.')
            # Print error
            self._check_process_exit()
            return None

        # Need to set up a DeviceInterface object that can be used to connect to the Pi.
        data_source = open_data_source(self.config)
        if data_source is None:
            self.LOGGER.error('Failed to open data source.')
            return None

        self.device_interface = DeviceInterface(data_source)

        # To test IMU data, enable the IMUOutput message on the diagnostic port.
        # NOTE: This will leave unsaved UserConfig changes on the device.
        if not self.env_args.HITL_BUILD_TYPE.is_gnss_only():
            self.LOGGER.info(f'Enabling IMUOutput message.')
            if not enable_imu_output(self.device_interface):
                self.LOGGER.error('Enabling IMUOutput failed.')
                return None

        return self.device_interface

    def shutdown_device(self, tests_passed: bool, output_dir: Path) -> bool:
        exit_succeeded = True
        if self.config.tcp_address is None or self.device_interface is None:
            return True

        # Stop the current log.
        if self.device_interface is not None:
            namespace_args = Namespace()
            namespace_args.type = 'log'
            exit_succeeded &= request_shutdown(self.device_interface, namespace_args)
            self.device_interface.data_source.stop()

        # Upload new device log after failure.
        if not tests_passed:
            # Extract latest Log ID from remote device. This line extracts the target of the symbolic link
            # /logs/current_log and then parses out the log ID.
            if self.env_args.HITL_BUILD_TYPE == DeviceType.ZIPLINE:
                log_data_path = "/home/pointone/p1_fusion_engine/cache/logs/console.txt"
            else:
                log_data_path = "/logs/current_log"

            stdin, stdout, stderr = self.ssh_client.exec_command("echo $(basename $(ls -l %s | awk -F'-> ' '{print $2}'))" % log_data_path)
            error = stderr.read().decode()
            if error:
                self.LOGGER.error(f"Error extracting log data on device: {error}")

            else:
                log_data = stdout.read().decode()

                scp = SCPClient(self.ssh_client.get_transport())
                if self.env_args.HITL_BUILD_TYPE == DeviceType.ZIPLINE:
                    scp.get(log_data_path, output_dir, recursive=True)
                else:
                    scp.get(log_data_path, '/logs', recursive=True)

                    # Add log ID to log list.
                    with open(output_dir / UPLOADED_LOG_LIST_FILE, 'w') as fd:
                        # Write to file.
                        fd.write(log_data)

        # Stop the process.
        if self.ssh_client is not None and self.ssh_channel is not None:
            self.LOGGER.info('Stopping process.')
            self.ssh_client.exec_command(self.STOP_CMD)
            start_time = time.monotonic()
            while time.monotonic() - start_time < PROCESS_STOP_TIMEOUT_SEC:
                time.sleep(0.1)
                if self.ssh_channel.exit_status_ready():
                    self.LOGGER.info(f'Process exited after {time.monotonic() - start_time:0.1f}s.')
                    break

            exit_succeeded &= self._check_process_exit()
            self.ssh_client.close()

        return exit_succeeded
