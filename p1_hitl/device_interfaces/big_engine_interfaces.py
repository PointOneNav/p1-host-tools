import io
import logging
import os
import re
import time
from argparse import Namespace
from pathlib import Path
from typing import Any, Dict, Optional

import paramiko
from scp import SCPClient

from bin.check_cds import config_to_key
from bin.config_tool import request_shutdown
from p1_hitl.defs import UPLOADED_DEVICE_LOGS_LIST_FILE, HitlEnvArgs
from p1_hitl.get_build_artifacts import download_file
from p1_runner.device_interface import DeviceInterface
from p1_test_automation.devices_config import DeviceConfig, open_data_source

from .base_interfaces import HitlDeviceInterfaceBase
from .interface_utils import enable_imu_output

RESTART_WAIT_TIME_SEC = 10
PROCESS_STOP_TIMEOUT_SEC = 10
CONNECTION_TIMEOUT_SEC = 5
OUTPUT_PORT = 30200
DIAGNOSTIC_PORT = 30202

SSH_KEY_PATH = os.environ.get('HITL_SSH_KEY_PATH', str(Path.home() / '.ssh/id_ed25519'))
SSH_USERNAME = os.environ.get('HITL_SSH_USERNAME', 'pointone')

GNSS_CONFIG_PATCH_PATH = f'/home/{SSH_USERNAME}/p1_fusion_engine/gnss_config_patch.json'


class HitlBigEngineInterface(HitlDeviceInterfaceBase):
    LOGGER = logging.getLogger('point_one.hitl.hitl_interface')
    LOG_DIR = Path('/logs')
    # NOTE: This is going to be wrapped in additional environment variables and arguments to support specifying
    # corrections and lever arms. This means that it must be a single command with no redirection. See the additional
    # parameters to make sure they are supported by the runscript for all platforms. It will also be wrapped in an
    # explicit call to bash which might interfere with single quotes in the command.
    RUNNER_CMD = './p1_fusion_engine/run_fusion_engine.sh --params-path ./fusion_engine_parameters.sh'
    # NOTE: This assumes the process binary is named `fusion_engine`. This may need to be child class specific
    # if this can't be assumed.
    STOP_CMD = 'pkill -SIGTERM -e fusion_engine'
    KILL_CMD = 'pkill -SIGKILL -e fusion_engine'

    @staticmethod
    def get_device_config(args: HitlEnvArgs) -> Optional[DeviceConfig]:
        fields = ['JENKINS_LAN_IP']
        if not args.HITL_BUILD_TYPE.is_gnss_only():
            fields.append('JENKINS_COARSE_ORIENTATION')
        if not args.check_fields(fields):
            return None
        else:
            # Interface is TCP3, which is configured as the diagnostic port.
            return DeviceConfig(name=args.HITL_NAME,
                                tcp_address=args.JENKINS_LAN_IP,
                                port=DIAGNOSTIC_PORT
                                )

    def __init__(self, config: DeviceConfig, env_args: HitlEnvArgs):
        self.config = config
        self.env_args = env_args
        self.device_interface: Optional[DeviceInterface] = None
        self.ssh_client: Optional[paramiko.SSHClient] = None
        self.ssh_channel: Optional[paramiko.Channel] = None

    def _check_process_exit(self) -> bool:
        if self.ssh_client is not None and self.ssh_channel is not None:
            if not self.ssh_channel.exit_status_ready():
                self.LOGGER.error('FE process still running after shutdown timeout.')
                return False
            elif not self.ssh_channel.recv_ready():
                self.LOGGER.error("Missing return code string.")
                return False
            else:
                console_output = ''
                # Even if process is ended, may need multiple reads.
                while True:
                    read_str = self.ssh_channel.recv(10240).decode(errors='ignore')
                    if len(read_str) == 0:
                        break
                    console_output += read_str

                parts = console_output.split(':')
                try:
                    ret_code = int(parts[-1])
                    # return codes > 128 indicate a signal triggered the termination (subtract 128 for the error code to
                    # get the corresponding signal). Codes 1,2,9,10,12-15 are signals that may be generated by external
                    # sources (SIGHUP, SIGKILL, etc.) so they don't indicate an internal failure.
                    # https://man7.org/linux/man-pages/man7/signal.7.html
                    # https://faculty.cs.niu.edu/~hutchins/csci480/signals.htm
                    if ret_code in [0, 129, 130, 137, 138, 140, 141, 142, 143]:
                        self.LOGGER.info(f"FE process exited successfully with code: {ret_code}")
                        return True
                    else:
                        self.LOGGER.error(f"FE process exited with error code: {ret_code}")
                        self.LOGGER.error("Process final output:\n" + ('=' * 80) + '\n' + console_output + ('=' * 80))
                        return False
                except ValueError as e:
                    self.LOGGER.error(f"Could not parse return code: {e}")
                    return False
        self.LOGGER.warning(f"FE process wasn't started.")
        return True

    def _write_imu_patch(self, scp: SCPClient):
        fd = io.StringIO()
        # For type checking.
        assert self.env_args.JENKINS_COARSE_ORIENTATION is not None
        fd.write('''\
{{
    "sensors": {{
        "imus/0": {{
            "c_ds": {{
                "values": [
                    {}, {}, {},
                    {}, {}, {},
                    {}, {}, {}
                ]
            }}
        }}
    }},
    "comm_interfaces": {{
        "tcp_sockets/2": {{
            "output_rates": {{
                "fusion_engine_rates": {{
                    "imu_output": "ON_CHANGE"
                }}
            }}
        }}
    }}
}}
'''.format(*config_to_key(self.env_args.JENKINS_COARSE_ORIENTATION)))
        fd.seek(0)
        scp.putfo(fd, GNSS_CONFIG_PATCH_PATH)

    def init_device(self, build_info: Dict[str, Any], skip_reset=False,
                    skip_corrections=False) -> Optional[DeviceInterface]:
        # build_info example:
        # {
        #     "timestamp": 1725918926,
        #     "version": "v2.1.0-917-g7e74d1b235",
        #     "git_hash": "7e74d1b2356165d0e4408aa665ebf214e8a6dcb3",
        #     "aws_path": "s3://pointone-build-artifacts/nautilus/quectel/v2.1.0-917-g7e74d1b235/"
        # }

        self.LOGGER.info(f'Initializing {self.env_args.HITL_BUILD_TYPE.name}.')

        if self.config.tcp_address is None:
            raise KeyError('Config missing TCP address.')

        pkey = paramiko.Ed25519Key.from_private_key_file(SSH_KEY_PATH)

        # Set up SSH automation tool.
        ssh_client = paramiko.SSHClient()
        ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
        self.LOGGER.info(f'Attempting to connect to TCP address {self.config.tcp_address}')
        try:
            ssh_client.connect(self.config.tcp_address, username=SSH_USERNAME, pkey=pkey, timeout=CONNECTION_TIMEOUT_SEC)
        except Exception as e:
            self.LOGGER.error("Failed to connect to TCP address %s: %s" % (self.config.tcp_address, str(e)))
            return None

        # Check for successful connection.
        transport = ssh_client.get_transport()
        if transport is None or not transport.is_active():
            self.LOGGER.error('Failed to connect to TCP address.')
            return None

        ################# Step 1: Install Engine on CPU #####################

        # Stop any existing runs.
        ssh_client.exec_command(self.KILL_CMD)
        # Clear all files from previous runs.
        self.LOGGER.info("Clearing data from previous runs.")
        ssh_client.exec_command("rm -rf p1_fusion_engine*")

        # Clear all previously recorded logs.
        ssh_client.exec_command(f"rm -rf {self.LOG_DIR}/*")

        # Download release from S3.
        aws_path = build_info["aws_path"]
        tar_pattern = r'.+\.tar\.gz'
        tar_filename = 'p1_fusion_engine.tar.gz'

        fd = io.BytesIO()

        if not download_file(fd, aws_path, tar_pattern):
            self.LOGGER.error("Failed to download file %s from %s" % (tar_pattern, aws_path))
            return None

        fd.seek(0)
        scp = SCPClient(transport)
        scp.putfo(fd, f'/home/{SSH_USERNAME}/{tar_filename}')

        # Unzip the tar file.
        _stdin, _stdout, _stderr = ssh_client.exec_command(f"tar -xzf {tar_filename}")
        # Wait for exit status to ensure that tar command finished executing.
        exit_status = _stdout.channel.recv_exit_status()

        # Run bootstrap script.
        channel = transport.open_session()
        self.ssh_client = ssh_client
        self.ssh_channel = channel

        RUNNER_CMD_PREFIX = ''
        if skip_corrections:
            # This is made a little confusing by the sshd_config AcceptEnv parameter. I believe this means we can use
            # the paramiko set_environment_variable or other methods for passing in environment variables. However,
            # using normal shell methods within the SSH session to set environment variables still works.
            #
            # The scripts are setup not to override this value if it is set and to default to "auto" otherwise.
            RUNNER_CMD_PREFIX = 'CORRECTIONS_SOURCE="none" '

        self.LOGGER.info('Starting engine.')

        gnss_config_patch_args = ''
        # To test IMU data, set the coarse orientation (c_ds) and enable the IMUOutput message on the diagnostic port.
        # We do this with a patch so that the engine starts up with the right settings.
        if not self.env_args.HITL_BUILD_TYPE.is_gnss_only():
            self._write_imu_patch(scp)
            gnss_config_patch_args = f' --user-config-patch={GNSS_CONFIG_PATCH_PATH}'

        ################# Step 2: Run Engine #####################

        # From https://docs.paramiko.org/en/stable/api/channel.html:
        # Because SSH2 has a windowing kind of flow control, if you stop reading data from a Channel and its buffer
        # fills up, the server will be unable to send you any more data until you read some of it. To handle this, all
        # output is passed into tail to avoid needing to continuously read data over the SSH connection. This creates an
        # issue where the return code of this call is the exit code of `tail`. Using `PIPESTATUS` gets the exit code of
        # the FE process dumped to stdout.
        #
        # On top of that, some platforms use sh instead of bash as their default shell. That would not properly
        # interpret this command. To get around this, we explicitly run the command in bash.
        BUFFER_OUTPUT_AND_EXIT_CODE = r' 2>&1 | tail -n 100; echo Exit Code:${PIPESTATUS[0]}'
        channel.set_combine_stderr(True)
        full_bash_cmd = RUNNER_CMD_PREFIX + self.RUNNER_CMD + gnss_config_patch_args + BUFFER_OUTPUT_AND_EXIT_CODE
        full_run_cmd = f"bash -c '{full_bash_cmd}'"
        self.LOGGER.info(full_run_cmd)
        channel.exec_command(full_run_cmd)
        # Manually wait to ensure that the bootstrap script kicks off in the background before continuing.
        time.sleep(RESTART_WAIT_TIME_SEC)

        # See if bootstrap script exited early.
        if channel.exit_status_ready():
            self.LOGGER.error('Fusion engine process exited prematurely.')
            # Print error
            self._check_process_exit()
            return None

        # Need to set up a DeviceInterface object that can be used to connect to the Pi.
        data_source = open_data_source(self.config)
        if data_source is None:
            self.LOGGER.error('Failed to open data source.')
            return None

        self.device_interface = DeviceInterface(data_source)

        return self.device_interface

    def shutdown_device(self, tests_passed: bool, output_dir: Path) -> bool:
        exit_succeeded = True
        if self.config.tcp_address is None or self.device_interface is None:
            return True

        # Stop the current log.
        if self.device_interface is not None:
            namespace_args = Namespace()
            namespace_args.type = 'log'
            exit_succeeded &= request_shutdown(self.device_interface, namespace_args)
            self.device_interface.data_source.stop()

        if self.ssh_client is not None:
            # Find log results on the DUT
            transport = self.ssh_client.get_transport()
            log_path = None
            if transport is not None:
                # Extract latest Log ID from remote device by extracting the target of the symbolic link
                # /logs/current_log.
                _, stdout, _ = self.ssh_client.exec_command(f'ls {self.LOG_DIR}/*/*')
                ls_output = stdout.read().decode()
                scp = SCPClient(transport)
                logs_found = False
                # Find `ls` results that look like:
                # ```
                # /logs/2025-04-17/heading-secondary:
                # d65b89970f9342a4af6c20d96c3efc86
                # ```
                for match in re.finditer(r'(/logs/[\d-]+/.+):\n([a-z0-9]+)', ls_output):
                    logs_found = True
                    log_path = f'{match.group(1)}/{match.group(2)}'
                    self.LOGGER.info(f"Big engine generated log {log_path}.")
                    # Upload new device log after failure.
                    if not tests_passed:
                        scp.get(log_path, '/logs', recursive=True)

                        # Add log ID to log list.
                        relative_path = Path(log_path).relative_to(self.LOG_DIR)
                        self.LOGGER.info(f"Adding log {relative_path} from device to log upload list.")
                        with open(output_dir / UPLOADED_DEVICE_LOGS_LIST_FILE, 'w') as fd:
                            # Write to file.
                            fd.write(str(relative_path) + '\n')

                if not logs_found:
                    self.LOGGER.error(f"Error extracting log data on device. `ls` output: {ls_output}")

                # Upload new device log after failure.
                if not tests_passed and log_path is not None:
                    scp = SCPClient(transport)
                    scp.get(log_path, '/logs', recursive=True)

                    # Add log ID to log list.
                    relative_path = Path(log_path).relative_to(self.LOG_DIR)
                    self.LOGGER.info(f"Adding log {relative_path} from device to log upload list.")
                    with open(output_dir / UPLOADED_DEVICE_LOGS_LIST_FILE, 'w') as fd:
                        # Write to file.
                        fd.write(str(relative_path) + '\n')

            # Stop the process.
            if self.ssh_channel is not None:
                self.LOGGER.info('Stopping process.')
                self.ssh_client.exec_command(self.STOP_CMD)
                start_time = time.monotonic()
                while time.monotonic() - start_time < PROCESS_STOP_TIMEOUT_SEC:
                    time.sleep(0.1)
                    if self.ssh_channel.exit_status_ready():
                        self.LOGGER.info(f'Process exited after {time.monotonic() - start_time:0.1f}s.')
                        break

                exit_succeeded &= self._check_process_exit()
                self.ssh_client.close()

                return exit_succeeded

        # self.ssh_client is None or self.ssh_channel is None
        self.LOGGER.info("SSH client closed before shutdown.")
        return False
